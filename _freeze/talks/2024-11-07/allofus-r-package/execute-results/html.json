{
  "hash": "52ecfe6b453f15247620945d3c26de74",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"allofus: an R package to facilitate use of the *All of Us* Researcher Workbench <br><br>\"\ntitle-slide-attributes:\n  data-background-image: \"roux-title-image.jpg\"\n  data-background-size: cover\n  data-background-opacity: \"0.5\"\n  logo: none\nauthor:\n  - name: Louisa Smith, PhD\n    affiliation: \n      - The Roux Institute at Northeastern University\n      - Bouve College of Health Sciences, Northeastern University\n  - name: Rob Cavanaugh, PhD\n    affiliation: \n      - The Roux Institute at Northeastern University\nformat:\n  revealjs:\n    slide-number: \"c\"\n    logo: \"roux-rb.png\"  # This will appear on all slides except title\n    theme: [simple, custom.scss]\n    css: style.css\n    controls: true\nexecute:\n  echo: true\n  message: true\n  warning: true\n  error: true\n  # eval: false\n  freeze: true\n  cache: true\ninclude-after: |\n  <script type=\"text/javascript\">\n    Reveal.on('ready', event => {\n      if (event.indexh === 0) {\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n      }\n    });\n    Reveal.addEventListener('slidechanged', (event) => {\n      if (event.indexh === 0) {\n        Reveal.configure({ slideNumber: null });\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = \"none\";\n      }\n      if (event.indexh === 1) {\n        Reveal.configure({ slideNumber: 'c' });\n        document.querySelector(\"div.has-logo > img.slide-logo\").style.display = null;\n      }\n    });\n  </script>\n---\n\n\n\n## Who we are {.smaller}\n\n:::::: columns\n::: {.column width=\"45%\"}\n![](images/neu_headshotA_square_circle.jpeg){style=\"border-radius:50%;\" width=\"300\"}\n\n*Assistant professor*\n\n-   causal inference, missing data and selection bias, pregnancy and reproductive health\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n![](images/clipboard-3214775132.png){style=\"border-radius:50%;\" width=\"300\"}\n\n*Research data analyst*\n\n-   health services research, neurorehabilitation, open-source software development\n:::\n::::::\n\n. . .\n\n**mentoring other researchers using *All of Us* data**\n\n## Challenges {.smaller}\n\n-   Lack of programming skills\n    -   Health researchers often use R or SAS, some use python, few use SQL\n    -   `tidyverse` is (the most?) popular framework for R\n-   *All of Us* data is complex\n    -   the OMOP CDM has a steep learning curve, plus the complexity of the other data (e.g., surveys)\n    -   many researchers are trained on cleaner, more straightforward data\n-   Large scale observational health research is hard\n    -   defining cohorts with appropriate inclusion/exclusion criteria, exposure/outcome phenotypes, time under observation, etc.\n    -   huge potential for confounding, selection bias, measurement error...\n    -   reproducibility is critical\n\n## `allofus` R package\n\n:::::: columns\n::: {.column width=\"70%\"}\n![](images/workflow.png)\n:::\n\n:::: {.column width=\"30%\"}\n::: incremental\n-   Build on existing tools/skills\n-   Enable complex research\n-   Efficient\n-   Reproducible\n:::\n::::\n::::::\n\n## When to start antihypertensive medications during pregnancy? {.smaller}\n\n+--------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Eligibility criteria** | Pregnant, with chronic hypertension diagnosed prior to pregnancy but no prior use of antihypertensive medications                                             |\n+--------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Baseline (time zero)** | First prenatal visit                                                                                                                                          |\n+--------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Treatment strategies** | Initiate antihypertensive medications 1) immediately vs. 2) delayed vs. 3) never                                                                              |\n+--------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| **Outcome**              | Composite of preeclampsia with severe features, medically indicated preterm birth at \\<35 weeks of gestation, placental abruption, or fetal or neonatal death |\n+--------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n## When to start antihypertensive medications during pregnancy?\n\n[1. Define the cohort]{.fragment fragment-index=\"1\"}\n\n[2. Extract data from different domains to create a dataset with exposure, outcome, covariates]{.fragment fragment-index=\"2\"}\n\n[3. Analyze the data]{.fragment .fade-in-then-semi-out fragment-index=\"3\" style=\"color:darkgrey\"}\n\n::: r-stack\n![](images/clipboard-3380727214.png){.fragment fragment-index=\"1\"}\n\n![](images/clipboard-1434146805.png){.fragment fragment-index=\"2\"}\n:::\n\n## Where to begin?\n\n![](images/clipboard-2973991945.png)\n\n<!-- ## Motivations -->\n\n<!-- -   Desire to make code easily readable and reproducible, particularly when creating complex cohorts and datasets -->\n\n<!-- -   Parallel work in OMOP data – want to take advantage of OHDSI tools -->\n\n<!-- -   Students want to use *All of Us* but find it overwhelming -->\n\n<!-- -   Familiarity with `tidyverse` packages and a lot of other tools built off the same framework -->\n\n<!-- -   As we were doing analyses, we were creating a lot of code we wanted to reuse -->\n\n## Begin in R\n\nEverything is built on a direct connection to the *bigquery* database\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(allofus)\nlibrary(tidyverse)\n\ncon <- aou_connect()\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError:\n! Unable to connect to CDR\n```\n\n\n:::\n:::\n\n\n\n## Access tables\n\nUnder the hood, [`dbplyr`](https://dbplyr.tidyverse.org/) (part of the `tidyverse`) allows researchers to use many of the same functions on a remote table that they would use on a dataframe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperson <- tbl(con, \"person\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: object 'con' not found\n```\n\n\n:::\n\n```{.r .cell-code}\ncolnames(person)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n## Quick data manipulations and computations\n\nUsers are running SQL queries without realizing they're running SQL queries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperson |>\n  mutate(birth_decade = cut(year_of_birth, \n                            breaks = c(1930, 1940, 1950, 1960, 1970, \n                                       1980, 1990, 2000, 2010))) |>\n  count(birth_decade)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in UseMethod(\"mutate\"): no applicable method for 'mutate' applied to an object of class \"function\"\n```\n\n\n:::\n:::\n\n\n\n## Behind the scenes\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.sql .cell-code}\nSELECT `birth_decade`, count(*) AS `n`\nFROM (\n  SELECT\n    `person`.*,\n    CASE\nWHEN (`year_of_birth` <= 1930.0) THEN NULL\nWHEN (`year_of_birth` <= 1940.0) THEN '(1930,1940]'\nWHEN (`year_of_birth` <= 1950.0) THEN '(1940,1950]'\nWHEN (`year_of_birth` <= 1960.0) THEN '(1950,1960]'\nWHEN (`year_of_birth` <= 1970.0) THEN '(1960,1970]'\nWHEN (`year_of_birth` <= 1980.0) THEN '(1970,1980]'\nWHEN (`year_of_birth` <= 1990.0) THEN '(1980,1990]'\nWHEN (`year_of_birth` <= 2000.0) THEN '(1990,2000]'\nWHEN (`year_of_birth` <= 2010.0) THEN '(2000,2010]'\nWHEN (`year_of_birth` > 2010.0) THEN NULL\nEND AS `birth_decade`\n  FROM `person`\n) `q01`\nGROUP BY `birth_decade`\n```\n:::\n\n\n\n## Creating cohorts with Cohort Builder\n\n![](images/clipboard-1754030645.png)\n\n## Creating cohorts with `allofus`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreproductive_age_female <- tbl(con, \"cb_search_person\") |> \n  filter(age_at_consent >= 18 & age_at_consent <= 55, \n         sex_at_birth == \"Female\")\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: object 'con' not found\n```\n\n\n:::\n\n```{.r .cell-code}\nhypertensive_disorder <- tbl(con, \"concept_ancestor\") |> \n  filter(ancestor_concept_id == 316866) |> \n  inner_join(\n    tbl(con, \"condition_occurrence\"), \n    by = join_by(descendant_concept_id == condition_concept_id)) |> \n  distinct(person_id)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: object 'con' not found\n```\n\n\n:::\n\n```{.r .cell-code}\ncohort <- reproductive_age_female |> \n  inner_join(hypertensive_disorder, by = join_by(person_id))\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: object 'reproductive_age_female' not found\n```\n\n\n:::\n\n```{.r .cell-code}\ntally(cohort)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError: object 'cohort' not found\n```\n\n\n:::\n:::\n\n\n\n## How does this address our challenges?\n\n::::: columns\n::: {.column width=\"65%\"}\n-   Abstracts away all the SQL code and take advantage of existing R skills\n-   Enables more complex cohort definitions, including those involving non-EHR data\n-   Easy to carry forward the cohort to extract data and create datasets\n-   Readable and reproducible\n:::\n\n::: {.column width=\"35%\"}\n![](images/clipboard-1268433413.png)\n:::\n:::::\n\n## Creating datasets with Cohort Builder\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(bigrquery)\n\n# This query represents dataset \"hypertension in pregnancy\" for domain \"person\" and was generated for All of Us Registered Tier Dataset v7\ndataset_71250616_person_sql <- paste(\"\n    SELECT\n        person.person_id,\n        person.gender_concept_id,\n        p_gender_concept.concept_name as gender,\n        person.birth_datetime as date_of_birth,\n        person.race_concept_id,\n        p_race_concept.concept_name as race,\n        person.ethnicity_concept_id,\n        p_ethnicity_concept.concept_name as ethnicity,\n        person.sex_at_birth_concept_id,\n        p_sex_at_birth_concept.concept_name as sex_at_birth \n    FROM\n        `person` person \n    LEFT JOIN\n        `concept` p_gender_concept \n            ON person.gender_concept_id = p_gender_concept.concept_id \n    LEFT JOIN\n        `concept` p_race_concept \n            ON person.race_concept_id = p_race_concept.concept_id \n    LEFT JOIN\n        `concept` p_ethnicity_concept \n            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n    LEFT JOIN\n        `concept` p_sex_at_birth_concept \n            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n    WHERE\n        person.PERSON_ID IN (SELECT\n            distinct person_id  \n        FROM\n            `cb_search_person` cb_search_person  \n        WHERE\n            cb_search_person.person_id IN (SELECT\n                person_id \n            FROM\n                `cb_search_person` p \n            WHERE\n                age_at_consent BETWEEN 18 AND 50 \n            AND cb_search_person.person_id IN (SELECT\n                person_id \n            FROM\n                `person` p \n            WHERE\n                sex_at_birth_concept_id IN (45878463) ) \n            AND cb_search_person.person_id IN (SELECT\n                criteria.person_id \n            FROM\n                (SELECT\n                    DISTINCT person_id, entry_date, concept_id \n                FROM\n                    `cb_search_all_events` \n                WHERE\n                    (concept_id IN(SELECT\n                        DISTINCT c.concept_id \n                    FROM\n                        `cb_criteria` c \n                    JOIN\n                        (SELECT\n                            CAST(cr.id as string) AS id       \n                        FROM\n                            `cb_criteria` cr       \n                        WHERE\n                            concept_id IN (316866)       \n                            AND full_text LIKE '%_rank1]%'      ) a \n                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                            OR c.path LIKE CONCAT('%.', a.id) \n                            OR c.path LIKE CONCAT(a.id, '.%') \n                            OR c.path = a.id) \n                    WHERE\n                        is_standard = 1 \n                        AND is_selectable = 1) \n                    AND is_standard = 1 )) criteria ) )\", sep=\"\")\n\n# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n#       But data exported on a different days will write to a new location so that historical\n#       copies can be kept as the dataset definition is changed.\nperson_71250616_path <- file.path(\n  Sys.getenv(\"WORKSPACE_BUCKET\"),\n  \"bq_exports\",\n  Sys.getenv(\"OWNER_EMAIL\"),\n  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n  \"person_71250616\",\n  \"person_71250616_*.csv\")\nmessage(str_glue('The data will be written to {person_71250616_path}. Use this path when reading ',\n                 'the data into your notebooks in the future.'))\n\n# Perform the query and export the dataset to Cloud Storage as CSV files.\n# NOTE: You only need to run `bq_table_save` once. After that, you can\n#       just read data from the CSVs in Cloud Storage.\nbq_table_save(\n  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_71250616_person_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n  person_71250616_path,\n  destination_format = \"CSV\")\n\n\n# Read the data directly from Cloud Storage into memory.\n# NOTE: Alternatively you can `gsutil -m cp {person_71250616_path}` to copy these files\n#       to the Jupyter disk.\nread_bq_export_from_workspace_bucket <- function(export_path) {\n  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())\n  bind_rows(\n    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n        function(csv) {\n          message(str_glue('Loading {csv}.'))\n          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n          if (is.null(col_types)) {\n            col_types <- spec(chunk)\n          }\n          chunk\n        }))\n}\ndataset_71250616_person_df <- read_bq_export_from_workspace_bucket(person_71250616_path)\n\ndim(dataset_71250616_person_df)\n\nhead(dataset_71250616_person_df, 5)\nlibrary(tidyverse)\nlibrary(bigrquery)\n\n# This query represents dataset \"hypertension in pregnancy\" for domain \"condition\" and was generated for All of Us Registered Tier Dataset v7\ndataset_71250616_condition_sql <- paste(\"\n    SELECT\n        c_occurrence.person_id,\n        c_occurrence.condition_concept_id,\n        c_standard_concept.concept_name as standard_concept_name,\n        c_standard_concept.concept_code as standard_concept_code,\n        c_standard_concept.vocabulary_id as standard_vocabulary,\n        c_occurrence.condition_start_datetime,\n        c_occurrence.condition_end_datetime,\n        c_occurrence.condition_type_concept_id,\n        c_type.concept_name as condition_type_concept_name,\n        c_occurrence.stop_reason,\n        c_occurrence.visit_occurrence_id,\n        visit.concept_name as visit_occurrence_concept_name,\n        c_occurrence.condition_source_value,\n        c_occurrence.condition_source_concept_id,\n        c_source_concept.concept_name as source_concept_name,\n        c_source_concept.concept_code as source_concept_code,\n        c_source_concept.vocabulary_id as source_vocabulary,\n        c_occurrence.condition_status_source_value,\n        c_occurrence.condition_status_concept_id,\n        c_status.concept_name as condition_status_concept_name \n    FROM\n        ( SELECT\n            * \n        FROM\n            `condition_occurrence` c_occurrence \n        WHERE\n            (\n                condition_concept_id IN (SELECT\n                    DISTINCT c.concept_id \n                FROM\n                    `cb_criteria` c \n                JOIN\n                    (SELECT\n                        CAST(cr.id as string) AS id       \n                    FROM\n                        `cb_criteria` cr       \n                    WHERE\n                        concept_id IN (132685, 133816, 134414, 135601, 136743, 137613, 138811, 141084, 314090, 35622939, 4034096, 4057976, 4116344, 4283352, 433536, 438490, 439077, 439393, 443700)       \n                        AND full_text LIKE '%_rank1]%'      ) a \n                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                        OR c.path LIKE CONCAT('%.', a.id) \n                        OR c.path LIKE CONCAT(a.id, '.%') \n                        OR c.path = a.id) \n                WHERE\n                    is_standard = 1 \n                    AND is_selectable = 1)\n            )  \n            AND (\n                c_occurrence.PERSON_ID IN (SELECT\n                    distinct person_id  \n                FROM\n                    `cb_search_person` cb_search_person  \n                WHERE\n                    cb_search_person.person_id IN (SELECT\n                        person_id \n                    FROM\n                        `cb_search_person` p \n                    WHERE\n                        age_at_consent BETWEEN 18 AND 50 \n                    AND cb_search_person.person_id IN (SELECT\n                        person_id \n                    FROM\n                        `person` p \n                    WHERE\n                        sex_at_birth_concept_id IN (45878463) ) \n                    AND cb_search_person.person_id IN (SELECT\n                        criteria.person_id \n                    FROM\n                        (SELECT\n                            DISTINCT person_id, entry_date, concept_id \n                        FROM\n                            `cb_search_all_events` \n                        WHERE\n                            (concept_id IN(SELECT\n                                DISTINCT c.concept_id \n                            FROM\n                                `cb_criteria` c \n                            JOIN\n                                (SELECT\n                                    CAST(cr.id as string) AS id       \n                                FROM\n                                    `cb_criteria` cr       \n                                WHERE\n                                    concept_id IN (316866)       \n                                    AND full_text LIKE '%_rank1]%'      ) a \n                                    ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                                    OR c.path LIKE CONCAT('%.', a.id) \n                                    OR c.path LIKE CONCAT(a.id, '.%') \n                                    OR c.path = a.id) \n                            WHERE\n                                is_standard = 1 \n                                AND is_selectable = 1) \n                            AND is_standard = 1 )) criteria ) )\n            )) c_occurrence \n    LEFT JOIN\n        `concept` c_standard_concept \n            ON c_occurrence.condition_concept_id = c_standard_concept.concept_id \n    LEFT JOIN\n        `concept` c_type \n            ON c_occurrence.condition_type_concept_id = c_type.concept_id \n    LEFT JOIN\n        `visit_occurrence` v \n            ON c_occurrence.visit_occurrence_id = v.visit_occurrence_id \n    LEFT JOIN\n        `concept` visit \n            ON v.visit_concept_id = visit.concept_id \n    LEFT JOIN\n        `concept` c_source_concept \n            ON c_occurrence.condition_source_concept_id = c_source_concept.concept_id \n    LEFT JOIN\n        `concept` c_status \n            ON c_occurrence.condition_status_concept_id = c_status.concept_id\", sep=\"\")\n\n# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n#       But data exported on a different days will write to a new location so that historical\n#       copies can be kept as the dataset definition is changed.\ncondition_71250616_path <- file.path(\n  Sys.getenv(\"WORKSPACE_BUCKET\"),\n  \"bq_exports\",\n  Sys.getenv(\"OWNER_EMAIL\"),\n  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n  \"condition_71250616\",\n  \"condition_71250616_*.csv\")\nmessage(str_glue('The data will be written to {condition_71250616_path}. Use this path when reading ',\n                 'the data into your notebooks in the future.'))\n\n# Perform the query and export the dataset to Cloud Storage as CSV files.\n# NOTE: You only need to run `bq_table_save` once. After that, you can\n#       just read data from the CSVs in Cloud Storage.\nbq_table_save(\n  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_71250616_condition_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n  condition_71250616_path,\n  destination_format = \"CSV\")\n\n\n# Read the data directly from Cloud Storage into memory.\n# NOTE: Alternatively you can `gsutil -m cp {condition_71250616_path}` to copy these files\n#       to the Jupyter disk.\nread_bq_export_from_workspace_bucket <- function(export_path) {\n  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character(), condition_type_concept_name = col_character(), stop_reason = col_character(), visit_occurrence_concept_name = col_character(), condition_source_value = col_character(), source_concept_name = col_character(), source_concept_code = col_character(), source_vocabulary = col_character(), condition_status_source_value = col_character(), condition_status_concept_name = col_character())\n  bind_rows(\n    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n        function(csv) {\n          message(str_glue('Loading {csv}.'))\n          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n          if (is.null(col_types)) {\n            col_types <- spec(chunk)\n          }\n          chunk\n        }))\n}\ndataset_71250616_condition_df <- read_bq_export_from_workspace_bucket(condition_71250616_path)\n\ndim(dataset_71250616_condition_df)\n\nhead(dataset_71250616_condition_df, 5)\nlibrary(tidyverse)\nlibrary(bigrquery)\n\n# This query represents dataset \"hypertension in pregnancy\" for domain \"measurement\" and was generated for All of Us Registered Tier Dataset v7\ndataset_71250616_measurement_sql <- paste(\"\n    SELECT\n        measurement.person_id,\n        measurement.measurement_concept_id,\n        m_standard_concept.concept_name as standard_concept_name,\n        m_standard_concept.concept_code as standard_concept_code,\n        m_standard_concept.vocabulary_id as standard_vocabulary,\n        measurement.measurement_datetime,\n        measurement.measurement_type_concept_id,\n        m_type.concept_name as measurement_type_concept_name,\n        measurement.operator_concept_id,\n        m_operator.concept_name as operator_concept_name,\n        measurement.value_as_number,\n        measurement.value_as_concept_id,\n        m_value.concept_name as value_as_concept_name,\n        measurement.unit_concept_id,\n        m_unit.concept_name as unit_concept_name,\n        measurement.range_low,\n        measurement.range_high,\n        measurement.visit_occurrence_id,\n        m_visit.concept_name as visit_occurrence_concept_name,\n        measurement.measurement_source_value,\n        measurement.measurement_source_concept_id,\n        m_source_concept.concept_name as source_concept_name,\n        m_source_concept.concept_code as source_concept_code,\n        m_source_concept.vocabulary_id as source_vocabulary,\n        measurement.unit_source_value,\n        measurement.value_source_value \n    FROM\n        ( SELECT\n            * \n        FROM\n            `measurement` measurement \n        WHERE\n            (\n                measurement_concept_id IN (SELECT\n                    DISTINCT c.concept_id \n                FROM\n                    `cb_criteria` c \n                JOIN\n                    (SELECT\n                        CAST(cr.id as string) AS id       \n                    FROM\n                        `cb_criteria` cr       \n                    WHERE\n                        concept_id IN (21490851, 21490853, 3004249, 3005606, 3009395, 3012526, 3012888, 3013940, 3017490, 3018586, 3018592, 3018822, 3019962, 3027598, 3028737, 3031203, 3034703, 3035856, 36716965, 4060834, 40758413, 4152194, 4154790, 4232915, 4239021, 4248524, 4298393, 4302410, 44789315, 44789316)       \n                        AND full_text LIKE '%_rank1]%'      ) a \n                        ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                        OR c.path LIKE CONCAT('%.', a.id) \n                        OR c.path LIKE CONCAT(a.id, '.%') \n                        OR c.path = a.id) \n                WHERE\n                    is_standard = 1 \n                    AND is_selectable = 1)\n            )  \n            AND (\n                measurement.PERSON_ID IN (SELECT\n                    distinct person_id  \n                FROM\n                    `cb_search_person` cb_search_person  \n                WHERE\n                    cb_search_person.person_id IN (SELECT\n                        person_id \n                    FROM\n                        `cb_search_person` p \n                    WHERE\n                        age_at_consent BETWEEN 18 AND 50 \n                    AND cb_search_person.person_id IN (SELECT\n                        person_id \n                    FROM\n                        `person` p \n                    WHERE\n                        sex_at_birth_concept_id IN (45878463) ) \n                    AND cb_search_person.person_id IN (SELECT\n                        criteria.person_id \n                    FROM\n                        (SELECT\n                            DISTINCT person_id, entry_date, concept_id \n                        FROM\n                            `cb_search_all_events` \n                        WHERE\n                            (concept_id IN(SELECT\n                                DISTINCT c.concept_id \n                            FROM\n                                `cb_criteria` c \n                            JOIN\n                                (SELECT\n                                    CAST(cr.id as string) AS id       \n                                FROM\n                                    `cb_criteria` cr       \n                                WHERE\n                                    concept_id IN (316866)       \n                                    AND full_text LIKE '%_rank1]%'      ) a \n                                    ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                                    OR c.path LIKE CONCAT('%.', a.id) \n                                    OR c.path LIKE CONCAT(a.id, '.%') \n                                    OR c.path = a.id) \n                            WHERE\n                                is_standard = 1 \n                                AND is_selectable = 1) \n                            AND is_standard = 1 )) criteria ) )\n            )) measurement \n    LEFT JOIN\n        `concept` m_standard_concept \n            ON measurement.measurement_concept_id = m_standard_concept.concept_id \n    LEFT JOIN\n        `concept` m_type \n            ON measurement.measurement_type_concept_id = m_type.concept_id \n    LEFT JOIN\n        `concept` m_operator \n            ON measurement.operator_concept_id = m_operator.concept_id \n    LEFT JOIN\n        `concept` m_value \n            ON measurement.value_as_concept_id = m_value.concept_id \n    LEFT JOIN\n        `concept` m_unit \n            ON measurement.unit_concept_id = m_unit.concept_id \n    LEFT JOIn\n        `visit_occurrence` v \n            ON measurement.visit_occurrence_id = v.visit_occurrence_id \n    LEFT JOIN\n        `concept` m_visit \n            ON v.visit_concept_id = m_visit.concept_id \n    LEFT JOIN\n        `concept` m_source_concept \n            ON measurement.measurement_source_concept_id = m_source_concept.concept_id\", sep=\"\")\n\n# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n#       But data exported on a different days will write to a new location so that historical\n#       copies can be kept as the dataset definition is changed.\nmeasurement_71250616_path <- file.path(\n  Sys.getenv(\"WORKSPACE_BUCKET\"),\n  \"bq_exports\",\n  Sys.getenv(\"OWNER_EMAIL\"),\n  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n  \"measurement_71250616\",\n  \"measurement_71250616_*.csv\")\nmessage(str_glue('The data will be written to {measurement_71250616_path}. Use this path when reading ',\n                 'the data into your notebooks in the future.'))\n\n# Perform the query and export the dataset to Cloud Storage as CSV files.\n# NOTE: You only need to run `bq_table_save` once. After that, you can\n#       just read data from the CSVs in Cloud Storage.\nbq_table_save(\n  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_71250616_measurement_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n  measurement_71250616_path,\n  destination_format = \"CSV\")\n\n\n# Read the data directly from Cloud Storage into memory.\n# NOTE: Alternatively you can `gsutil -m cp {measurement_71250616_path}` to copy these files\n#       to the Jupyter disk.\nread_bq_export_from_workspace_bucket <- function(export_path) {\n  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character(), measurement_type_concept_name = col_character(), operator_concept_name = col_character(), value_as_concept_name = col_character(), unit_concept_name = col_character(), visit_occurrence_concept_name = col_character(), measurement_source_value = col_character(), source_concept_name = col_character(), source_concept_code = col_character(), source_vocabulary = col_character(), unit_source_value = col_character(), value_source_value = col_character())\n  bind_rows(\n    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n        function(csv) {\n          message(str_glue('Loading {csv}.'))\n          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n          if (is.null(col_types)) {\n            col_types <- spec(chunk)\n          }\n          chunk\n        }))\n}\ndataset_71250616_measurement_df <- read_bq_export_from_workspace_bucket(measurement_71250616_path)\n\ndim(dataset_71250616_measurement_df)\n\nhead(dataset_71250616_measurement_df, 5)\nlibrary(tidyverse)\nlibrary(bigrquery)\n\n# This query represents dataset \"hypertension in pregnancy\" for domain \"drug\" and was generated for All of Us Registered Tier Dataset v7\ndataset_71250616_drug_sql <- paste(\"\n    SELECT\n        d_exposure.person_id,\n        d_exposure.drug_concept_id,\n        d_standard_concept.concept_name as standard_concept_name,\n        d_standard_concept.concept_code as standard_concept_code,\n        d_standard_concept.vocabulary_id as standard_vocabulary,\n        d_exposure.drug_exposure_start_datetime,\n        d_exposure.drug_exposure_end_datetime,\n        d_exposure.verbatim_end_date,\n        d_exposure.drug_type_concept_id,\n        d_type.concept_name as drug_type_concept_name,\n        d_exposure.stop_reason,\n        d_exposure.refills,\n        d_exposure.quantity,\n        d_exposure.days_supply,\n        d_exposure.sig,\n        d_exposure.route_concept_id,\n        d_route.concept_name as route_concept_name,\n        d_exposure.lot_number,\n        d_exposure.visit_occurrence_id,\n        d_visit.concept_name as visit_occurrence_concept_name,\n        d_exposure.drug_source_value,\n        d_exposure.drug_source_concept_id,\n        d_source_concept.concept_name as source_concept_name,\n        d_source_concept.concept_code as source_concept_code,\n        d_source_concept.vocabulary_id as source_vocabulary,\n        d_exposure.route_source_value,\n        d_exposure.dose_unit_source_value \n    FROM\n        ( SELECT\n            * \n        FROM\n            `drug_exposure` d_exposure \n        WHERE\n            (\n                drug_concept_id IN (SELECT\n                    DISTINCT ca.descendant_id \n                FROM\n                    `cb_criteria_ancestor` ca \n                JOIN\n                    (SELECT\n                        DISTINCT c.concept_id       \n                    FROM\n                        `cb_criteria` c       \n                    JOIN\n                        (SELECT\n                            CAST(cr.id as string) AS id             \n                        FROM\n                            `cb_criteria` cr             \n                        WHERE\n                            concept_id IN (21601664, 21601744)             \n                            AND full_text LIKE '%_rank1]%'       ) a \n                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                            OR c.path LIKE CONCAT('%.', a.id) \n                            OR c.path LIKE CONCAT(a.id, '.%') \n                            OR c.path = a.id) \n                    WHERE\n                        is_standard = 1 \n                        AND is_selectable = 1) b \n                        ON (ca.ancestor_id = b.concept_id)))  \n                    AND (d_exposure.PERSON_ID IN (SELECT\n                        distinct person_id  \n                FROM\n                    `cb_search_person` cb_search_person  \n                WHERE\n                    cb_search_person.person_id IN (SELECT\n                        person_id \n                    FROM\n                        `cb_search_person` p \n                    WHERE\n                        age_at_consent BETWEEN 18 AND 50\n                    AND cb_search_person.person_id IN (SELECT\n                        person_id \n                    FROM\n                        `person` p \n                    WHERE\n                        sex_at_birth_concept_id IN (45878463) ) \n                    AND cb_search_person.person_id IN (SELECT\n                        criteria.person_id \n                    FROM\n                        (SELECT\n                            DISTINCT person_id, entry_date, concept_id \n                        FROM\n                            `cb_search_all_events` \n                        WHERE\n                            (concept_id IN(SELECT\n                                DISTINCT c.concept_id \n                            FROM\n                                `cb_criteria` c \n                            JOIN\n                                (SELECT\n                                    CAST(cr.id as string) AS id       \n                                FROM\n                                    `cb_criteria` cr       \n                                WHERE\n                                    concept_id IN (316866)       \n                                    AND full_text LIKE '%_rank1]%'      ) a \n                                    ON (c.path LIKE CONCAT('%.', a.id, '.%') \n                                    OR c.path LIKE CONCAT('%.', a.id) \n                                    OR c.path LIKE CONCAT(a.id, '.%') \n                                    OR c.path = a.id) \n                            WHERE\n                                is_standard = 1 \n                                AND is_selectable = 1) \n                            AND is_standard = 1 )) criteria ) )\n            )) d_exposure \n    LEFT JOIN\n        `concept` d_standard_concept \n            ON d_exposure.drug_concept_id = d_standard_concept.concept_id \n    LEFT JOIN\n        `concept` d_type \n            ON d_exposure.drug_type_concept_id = d_type.concept_id \n    LEFT JOIN\n        `concept` d_route \n            ON d_exposure.route_concept_id = d_route.concept_id \n    LEFT JOIN\n        `visit_occurrence` v \n            ON d_exposure.visit_occurrence_id = v.visit_occurrence_id \n    LEFT JOIN\n        `concept` d_visit \n            ON v.visit_concept_id = d_visit.concept_id \n    LEFT JOIN\n        `concept` d_source_concept \n            ON d_exposure.drug_source_concept_id = d_source_concept.concept_id\", sep=\"\")\n\n# Formulate a Cloud Storage destination path for the data exported from BigQuery.\n# NOTE: By default data exported multiple times on the same day will overwrite older copies.\n#       But data exported on a different days will write to a new location so that historical\n#       copies can be kept as the dataset definition is changed.\ndrug_71250616_path <- file.path(\n  Sys.getenv(\"WORKSPACE_BUCKET\"),\n  \"bq_exports\",\n  Sys.getenv(\"OWNER_EMAIL\"),\n  strftime(lubridate::now(), \"%Y%m%d\"),  # Comment out this line if you want the export to always overwrite.\n  \"drug_71250616\",\n  \"drug_71250616_*.csv\")\nmessage(str_glue('The data will be written to {drug_71250616_path}. Use this path when reading ',\n                 'the data into your notebooks in the future.'))\n\n# Perform the query and export the dataset to Cloud Storage as CSV files.\n# NOTE: You only need to run `bq_table_save` once. After that, you can\n#       just read data from the CSVs in Cloud Storage.\nbq_table_save(\n  bq_dataset_query(Sys.getenv(\"WORKSPACE_CDR\"), dataset_71250616_drug_sql, billing = Sys.getenv(\"GOOGLE_PROJECT\")),\n  drug_71250616_path,\n  destination_format = \"CSV\")\n\n\n# Read the data directly from Cloud Storage into memory.\n# NOTE: Alternatively you can `gsutil -m cp {drug_71250616_path}` to copy these files\n#       to the Jupyter disk.\nread_bq_export_from_workspace_bucket <- function(export_path) {\n  col_types <- cols(standard_concept_name = col_character(), standard_concept_code = col_character(), standard_vocabulary = col_character(), drug_type_concept_name = col_character(), stop_reason = col_character(), sig = col_character(), route_concept_name = col_character(), lot_number = col_character(), visit_occurrence_concept_name = col_character(), drug_source_value = col_character(), source_concept_name = col_character(), source_concept_code = col_character(), source_vocabulary = col_character(), route_source_value = col_character(), dose_unit_source_value = col_character())\n  bind_rows(\n    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),\n        function(csv) {\n          message(str_glue('Loading {csv}.'))\n          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)\n          if (is.null(col_types)) {\n            col_types <- spec(chunk)\n          }\n          chunk\n        }))\n}\ndataset_71250616_drug_df <- read_bq_export_from_workspace_bucket(drug_71250616_path)\n\ndim(dataset_71250616_drug_df)\n\nhead(dataset_71250616_drug_df, 5)\n```\n:::\n\n\n\n## Creating datasets with Cohort Builder\n\nI have 4 CSV files (over 6 million rows) stored in my bucket that I have to read back in to do more manipulation\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\ngs://fc-secure-5dd899cc-249c-449a-b4b1-96abcc51898b/bq_exports/\nlouisahsmith@researchallofus.org/20241106/person_71250616/\nperson_71250616_*.csv\n\ngs://fc-secure-5dd899cc-249c-449a-b4b1-96abcc51898b/bq_exports/\nlouisahsmith@researchallofus.org/20241106/condition_71250616/\ncondition_71250616_*.csv\n\ngs://fc-secure-5dd899cc-249c-449a-b4b1-96abcc51898b/bq_exports/\nlouisahsmith@researchallofus.org/20241106/measurement_71250616/\nmeasurement_71250616_*.csv\n\ngs://fc-secure-5dd899cc-249c-449a-b4b1-96abcc51898b/bq_exports/\nlouisahsmith@researchallofus.org/20241106/drug_71250616/drug_71250616_*.csv\n```\n\n\n:::\n:::\n\n\n\n## Creating datasets with `allofus`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconcept_ids <- c(21601664, 21601744, 21490851, 21490853, 3004249, 3005606, 3009395, 3012526, 3012888, 3013940, 3017490, 3018586, 3018592, 3018822, 3019962, 3027598, 3028737, 3031203, 3034703, 3035856, 36716965, 4060834, 40758413, 4152194, 4154790, 4232915, 4239021, 4248524, 4298393, 4302410, 44789315, 44789316, 132685, 133816, 134414, 135601, 136743, 137613, 138811, 141084, 314090, 35622939, 4034096, 4057976, 4116344, 4283352, 433536, 438490, 439077, 439393, 443700)\n\naou_concept_set(cohort, \n                concepts = concept_ids, \n                domains = c(\"drug\", \"measurement\", \"condition\"), \n                output = \"all\") |> \n  count(concept_name, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-error}\n\n```\nError in `aou_concept_set()`:\n! No connection available.\nℹ Provide a connection automatically by running `aou_connect()` before this\n  function.\nℹ You can also provide `con` as an argument or default with\n  `options(aou.default.con = ...)`.\n```\n\n\n:::\n:::\n\n\n\n## Easily introduce temporal relationships {.smaller}\n\nLet's imagine we have a pregnancy cohort with start date! [(10.1093/jamia/ocae195)](https://doi.org/10.1093/jamia/ocae195)\n\n<!-- [^1]: Smith LH, Wang W, Keefe-Oates B. Pregnancy episodes in *All of Us* : harnessing multi-source data for pregnancy-related research. *Journal of the American Medical Informatics Association*. 2024. doi: [10.1093/jamia/ocae195](https://doi.org/10.1093/jamia/ocae195) -->\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohort_no_drugs_prior <- aou_concept_set(pregnancy_cohort,\n                                         concepts = drug_concept_ids,\n                                         start_date = NULL,\n                                         end_date = \"pregnancy_start_date\",\n                                         domain = \"drug\", \n                                         output = \"indicator\",\n                                         concept_set_name = \"drugs_prior\") |> \n  filter(any_drugs_prior == 0)\n\ncohort_no_drugs_hypertension <- aou_concept_set(cohort_no_drugs_prior,\n                                                concepts = hypertension_concept_ids,\n                                                start_date = NULL,\n                                                end_date = \"pregnancy_start_date\",\n                                                domain = \"condition\", \n                                                output = \"indicator\",\n                                                concept_set_name = \"hypertension_prior\") |> \n  filter(hypertension_prior == 1)\n```\n:::\n\n\n\n![](images/clipboard-3380727214.png){fig-align=\"center\" width=\"700\"}\n\n## Easily introduce temporal relationships {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbp_during_and_prior <- aou_concept_set(cohort_no_drugs_hypertension,\n                                       concepts = bp_concept_ids,\n                                       start_date = NULL,\n                                       end_date = \"pregnancy_end_date\",\n                                       domain = \"measurement\", \n                                       output = \"all\")\n\nall_drugs_during <- aou_concept_set(cohort_no_drugs_hypertension,\n                                    concepts = drug_concept_ids,\n                                    start_date = \"pregnancy_start_date\",\n                                    end_date = \"pregnancy_end_date\",\n                                    domain = \"drug\", \n                                    output = \"all\")\n\npreeclampsia_outcomes <- aou_concept_set(cohort_no_drugs_hypertension,\n                                         concepts = preeclampsia_concept_ids,\n                                         start_date = \"pregnancy_start_date\",\n                                         end_date = \"pregnancy_end_date\",\n                                         domain = \"condition\", \n                                         output = \"all\")\n```\n:::\n\n\n\n![](images/clipboard-1434146805.png){fig-align=\"center\" width=\"700\"}\n\n## Improved efficiency\n\n-   We're extracting a lot less data because we are\n    1.  Immediately using it for what we need (eligibility criteria)\n    2.  Restricting to the time periods of interest\n-   The data is not actually extracted or stored until we need it in a local R session (e.g, for figures, regressions, etc.)\n-   Edits are straightforward and code is easily readable\n\n*vs. storing millions of rows of data in a bucket and transferring it every time you run a notebook*\n\n## When you do store data, we have functions for that! {.smaller .scrollable}\n\n+--------------------------+--------------------------------------------------------+--------------------+\n| Task                     | Workbench provided code snippet                        | `allofus` function |\n+==========================+========================================================+====================+\n| List files in the bucket | `# Get the bucket name`                                | `aou_ls_bucket()`  |\n|                          |                                                        |                    |\n|                          | `my_bucket <- Sys.getenv('WORKSPACE_BUCKET')`          |                    |\n|                          |                                                        |                    |\n|                          | `# List objects in the bucket`                         |                    |\n|                          |                                                        |                    |\n|                          | `system(paste0(\"gsutil ls -r \", my_bucket), intern=T)` |                    |\n+--------------------------+--------------------------------------------------------+--------------------+\n\n## When you do store data, we have functions for that! {.smaller .scrollable}\n\n+-----------------------------------------------+-----------------------------------------------------------------------------------------------------------+----------------------------------------+\n| Task                                          | Workbench provided code snippet                                                                           | `allofus` function                     |\n+===============================================+===========================================================================================================+========================================+\n| Move a file from the bucket to workspace disk | `# replace 'test.csv' with the name of the file in your google bucket (don't delete the quotation marks)` | `aou_bucket_to_workspace( \"test.csv\")` |\n|                                               |                                                                                                           |                                        |\n|                                               | `name_of_file_in_bucket <- 'test.csv'`                                                                    |                                        |\n|                                               |                                                                                                           |                                        |\n|                                               | `# Get the bucket name`                                                                                   |                                        |\n|                                               |                                                                                                           |                                        |\n|                                               | `my_bucket <- Sys.getenv('WORKSPACE_BUCKET')`                                                             |                                        |\n|                                               |                                                                                                           |                                        |\n|                                               | `# Copy the file from current workspace to the bucket`                                                    |                                        |\n|                                               |                                                                                                           |                                        |\n|                                               | `system(paste0(\"gsutil cp \", my_bucket, \"/data/\", name_of_file_in_bucket, \" .\"), intern=T)`               |                                        |\n|                                               |                                                                                                           |                                        |\n|                                               | `# Load the file into a dataframe`                                                                        |                                        |\n|                                               |                                                                                                           |                                        |\n|                                               | `my_dataframe <- read_csv(name_of_file_in_bucket)`                                                        |                                        |\n+-----------------------------------------------+-----------------------------------------------------------------------------------------------------------+----------------------------------------+\n\n## When you do store data, we have functions for that! {.smaller .scrollable}\n\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+\n| Task                                           | Workbench provided code snippet                                                                                         | `allofus` function                        |\n+================================================+=========================================================================================================================+===========================================+\n| Write a file to disk and move it to the bucket | `# Replace df with THE NAME OF YOUR DATAFRAME`                                                                          | `write.csv(df, \"test.csv\")`               |\n|                                                |                                                                                                                         |                                           |\n|                                                | `my_dataframe <- df`                                                                                                    | `aou_workspace_to_bucket(df, \"test.csv\")` |\n|                                                |                                                                                                                         |                                           |\n|                                                | `# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)` |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `destination_filename <- 'test.csv'`                                                                                    |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `# store the dataframe in current workspace`                                                                            |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `write_excel_csv(my_dataframe, destination_filename)`                                                                   |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `# Get the bucket name`                                                                                                 |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `my_bucket <- Sys.getenv('WORKSPACE_BUCKET')`                                                                           |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `# Copy the file from current workspace to the bucket`                                                                  |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `system(paste0(\"gsutil cp ./\", destination_filename, \" \", my_bucket, \"/data/\"), intern=T)`                              |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `# Check if file is in the bucket`                                                                                      |                                           |\n|                                                |                                                                                                                         |                                           |\n|                                                | `system(paste0(\"gsutil ls \", my_bucket, \"/data/*.csv\"), intern=T)`                                                      |                                           |\n+------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------+\n\n## Integrating OHDSI software for cohort building\n\n![](images/clipboard-2853603321.png){fig-align=\"center\"}\n\n## Survey data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey_data <- aou_survey(cohort,\n           questions = c(43529063),\n           question_output = c(\"hypertension\"))\n```\n:::\n\n\nWhen was the survey question answered?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(survey_data)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"person_id\"         \"hypertension\"      \"hypertension_date\"\n```\n\n\n:::\n:::\n\n\n\n## Survey data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncount(survey_data, hypertension)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  hypertension          n\n  <chr>             <dbl>\n1 <NA>              16229\n2 Yes                5579\n3 No                 4426\n4 Skip                280\n5 DontKnow             49\n6 PreferNotToAnswer     6\n```\n\n\n:::\n:::\n\n\n\n-   \"Skip/Prefer not to answer/Don't know\" includes anyone who skipped the whole question\n-   `NA` refers to participants who never saw the question.\n-   \"No\" assigned to respondents who answered the question, but didn't select \"Self\"\n\n## Harder to figure out appropriate denominator\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey_answers <- tbl(con, \"ds_survey\") |> \n  inner_join(cohort, by = join_by(person_id)) |> \n  filter(question_concept_id == 836787)\ncount(survey_answers, answer)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 2\n  answer                                                        n\n  <chr>                                                     <int>\n1 Including yourself, who ... (hypertension)? - Daughter      201\n2 Including yourself, who ... (hypertension)? - Father       4195\n3 Including yourself, who ... (hypertension)? - Grandparent  3915\n4 Including yourself, who ... (hypertension)? - Mother       4480\n5 Including yourself, who ... (hypertension)? - Self         5583\n6 Including yourself, who ... (hypertension)? - Sibling      2384\n7 Including yourself, who ... (hypertension)? - Son           213\n8 PMI: Skip                                                  1152\n```\n\n\n:::\n:::\n\n\n\n## Try to provide information to improve interpretability\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsurvey_data <- aou_survey(cohort,\n           questions = c(43530468),\n           question_output = c(\"hypertension_age_diagnosis\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nℹ One or more of the requested questions were only asked of people who responded that they had certain conditions.\n→ The top-level question(s) will be added to the output to provide context about missing data as column(s) `circulatorycondition_hypertension_yes`.\n    \n```\n\n\n:::\n:::\n\n\n\n\n\n## {background-iframe=\"https://roux-ohdsi.github.io/allofus/vignettes/web_only/searchable_codebook.html\" background-interactive=true}\n\n## {background-iframe=\"https://roux-ohdsi.github.io/allofus/vignettes/web_only/health_codebook.html\" background-interactive=true}\n\n## {background-iframe=\"https://roux-ohdsi.github.io/allofus/vignettes/data.html\" background-interactive=true}\n\n## Challenges (reprise)\n\n-   Lack of programming skills\n    -   **the `allofus` package allows users to mostly avoid SQL and use the popular `tidyverse` R framework**\n-   *All of Us* data is complex\n    -   **the `allofus` package allows for simpler methods of cohort and outcomes specification using the OMOP CDM data, including survey data in *All of Us***\n-   Large scale observational health research is hard\n    -   **the `allofus` package helps try to avoid (some) mistakes and make code intent clear**\n\n## On the agenda {.smaller}\n\n-   Lack of programming skills\n    -   Improve and extend functions and documentation\n    -   Expand the methods in this package to python\n    -   Ensure long-term stability and robustness for R package and python library\n-   *All of Us* data is complex\n    -   Build a suite a specific functions for genomics, fitbit data\n    -   Add integrations with existing OHDSI tools\n-   Large scale observational health research is hard\n    -   Scale up tutorials and training materials that go beyond how to query the data\n        -   creating causal models\n        -   defining and validating cohorts\n        -   understanding, identifying, and accounting for confounding and bias\n        -   dealing with missing data\n        -   training in appropriate statistical methods for observational health research\n\n## Thank you!\n\n- Smith LH, Cavanaugh R. allofus: an R package to facilitate use of the All of Us Researcher Workbench. Journal of the American Medical Informatics Association. 2024;ocae198. doi: [10.1093/jamia/ocae198](https://doi.org/10.1093/jamia/ocae198)\n- GitHub (source code, bug reports): [github.com/roux-ohdsi/allofus](https://github.com/roux-ohdsi/allofus)\n- Package site (tutorials, searchable codebooks): [roux-ohdsi.github.io/allofus](https://roux-ohdsi.github.io/allofus)\n- Email: <l.smith@northeastern.edu>; <r.cavanaugh@northeastern.edu>",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}